# 唇形同步的人脸视频生成技术

## 1. 项目背景

​	神经网络近期发展得擅长进行对话，但目前已有的方法仅仅建立在文本对话的基础上，缺乏人真正面对面交谈时的面部表情表达。同一句话同一个人用不同表情说出来，其表达的情绪是不一样的。CVPR2018的一篇关于机器人对话的论文中提出了一种神经对话模型，该模型的目标是阅读和生成面部手势以及文本。这使得我们的模型能够根据说话人的表情所的情绪调整自己的反应。其中特别介绍了一个RNN Encoder-Decoder，它利用面部肌肉的运动，以及语言的对话。译码器由两层组成，底层是为了产生语言反应和粗糙的面部表情，二层是为了填充细微的手势，使生成的输出更加流畅自然。本项目目标为复现Face2Face Model，通过使用250部电影对应的JSON数据文件来训练神经网络，通过自动度量和人类研究来产生更自然的对话，并用一个面对面聊天的头像来演示。

**参考文献**：Hang Chu, Daiqing Li, Sanja Fidler.A Face-to-Face Neural Conversation Model .[pdf][demo] In Computer Vision and Pattern Recognition (CVPR), 2018.

## 2.总体设计

## 3. 需求分析

### 3.1 综合描述

#### 3.1.1项目预期成果

真人语音不同表情视频输入，人脸语音同步表情视频输出

#### 3.1.2运行环境 

前端，Windows网页端显示; 后端，Linux Centos系统，PyCharm编译器，Python PyTorch框架

### 3.2 外部接口需求

#### 3.2.1用户界面

仿 NeuralHank Demo  https://www.sheep-electric.net/

![微信图片_20181025195936](C:\Users\qiang\Desktop\微信图片_20181025195936.png)

#### 3.2.2硬件接口

* 键盘按键接口
* 相机接口
* 麦克风接口 
* 扬声器接口

#### 3.2.3软件接口

* 数据集：MovieChat Dataset

* 函数库：PyTorch

* 第三方工具：

  ​	在用户界面图中，

  *　`1`使用一个Speech To Text API将语音转换为文本，作为神经对话模型输入的一部分
  *　`2`调用相机，使用OpenFace捕获人脸（FACS  Representation），生成表情数据，作为模型输入的另一部分
  *　`3`控制麦克风和扬声器的开关
  *　`4`从网络Response中获取模型输出，合成人脸视频展示，并使用Microsoft Speech API将输出文本转换为语音。
  *　`5`显示模型输出文本

*　​

#### 3.2.4通讯接口

HTTP协议：Okhttp3

### 3.3系统功能需求

### 3.4其它非功能需求



## 4.详细设计

## 5.开发计划

## 6.测试

 
